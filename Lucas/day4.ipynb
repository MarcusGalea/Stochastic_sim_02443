{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - Variance redudiction Methods\n",
    "\n",
    "The tasks centers around simlation of the integral $\\int_{0}^{1} e^x \\, \\mathrm{d}x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import scipy.stats as stats\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNCHANGED\n",
    "## 1) Simulation of the integral using a Crude Monte Carlo Method\n",
    "\n",
    "Using from the slides that the integral can be simplified to the expectation of $e^U$ where $U\\sim Uniform(0,1)$. Simulate $n = 100$ instances of $e^x$, and find the mean. To get a 95% CI, use quantiles from t distribution with $n-1$ dof and $\\alpha = 0.05$.\n",
    "\n",
    "$$CI = \\left[\\bar{\\theta} + \\frac{S_\\theta}{\\sqrt{n}}t_{\\frac{\\alpha}{2}} (n-1);\\bar{\\theta} + \\frac{S_\\theta}{\\sqrt{n}}t_{1-\\frac{\\alpha}{2}} (n-1) \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Crude Monte Carlo :\n",
      "Mean is 1.763, with 95% confidence interval [1.67,1.857]\n",
      "The true value of the integral is: 1.7183\n"
     ]
    }
   ],
   "source": [
    "def crudeMC(n):\n",
    "    U = rnd.uniform(size = n)\n",
    "    x = np.exp(U)\n",
    "    return x\n",
    "\n",
    "def meanVar(x):\n",
    "    mean = np.mean(x)\n",
    "    var = np.var(x)\n",
    "    return mean, var\n",
    "\n",
    "def tConf(x, alpha, string):\n",
    "    mean, var = meanVar(x)\n",
    "    dof = len(x) - 1\n",
    "    s = np.sqrt(var / len(x))\n",
    "    a = stats.t.ppf(alpha/2, dof)\n",
    "    b = stats.t.ppf(1 - alpha/2, dof)\n",
    "    print(\"For\", string, \":\")\n",
    "    print(f\"Mean is {round(mean,3)}, with 95% confidence interval [{round(mean + s * a,2)},{round(mean + s * b,3)}]\")\n",
    "\n",
    "alpha = 0.05\n",
    "n = 100\n",
    "Xs_crude = crudeMC(n)\n",
    "tConf(Xs_crude, alpha, \"Crude Monte Carlo\" )\n",
    "print(f\"The true value of the integral is: {round(np.exp(1) - np.exp(0),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNCHANGED\n",
    "### 2) Antithetic variables\n",
    "We can use Anithetic variables to exploit the fact that the integral $\\int_{-\\infty}^{\\infty} e^x \\, \\mathrm{d}x$ is monotonely increasing. In practice this means we can use a single uniformly distributed value $U\\sim Uniform(0,1)$, as in the Crude Monte Carlo Method, an use it to create a second uniformly distributed value $U-1$, almost for free. \n",
    "\n",
    "Using these we can create 2 estimates of the integral by $e^U$ and $e^{U-1}$, and take the average of these two to get a much more robust estimate of the integral\n",
    "\n",
    "$$Y_i = \\frac{e^{U_i - e^{U_i-1}}}{2}.$$\n",
    "\n",
    "The expectation of the integral is now\n",
    "\n",
    "$$E\\left(Y_i\\right).$$\n",
    "\n",
    "$Y_i$ which on the slides is proved to have variance $\\frac{1}{4} Var\\left(e^{U_i}\\right) + \\frac{1}{4} Var\\left(e^{1- U_i}\\right) + \\frac{1}{2} Cov\\left(e^{U_i}, e^{1- U_i}\\right)$. As $e^{U_i}$ and  $e^{1- U_i}$ are obviosly negatively correlated, this variance is much lower than before.\n",
    "\n",
    "By rewriting $Y_i$ computing cost can be lowered, to only calculate a single exponential, resulting in an only marginally more expensive computation for $n$ $Y$'s compared to $n$ $X$'s.\n",
    "\n",
    "$$Y_i = \\frac{e^{U_i + \\frac{e}{e^{U_i}}}}{2}.$$\n",
    "\n",
    "Note: Had the integral not been monotonely increasing, say we had attemted to estimate some other function $f$, we could have had a situation where $f\\left(U_i\\right)$ and $f\\left(U_i - 1\\right)$ had been positively correlated, which could lead to a higher variance on $Y_i$. For the exponential function one of $e^{U_i}$ and $e^{U_i-1}$ is always large, and one is always small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Antithetics Variables :\n",
      "Mean is 1.717, with 95% confidence interval [1.7,1.729]\n"
     ]
    }
   ],
   "source": [
    "def antithetic(n):\n",
    "    U = rnd.uniform(size = n)\n",
    "    t = np.exp(U)\n",
    "    Ys = 0.5 * (t + np.exp(1) / t )\n",
    "    return Ys\n",
    "Xs_antithetic = antithetic(100)\n",
    "tConf(Xs_antithetic, alpha, \"Antithetics Variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNCHANGED\n",
    "### 3) Control Variates\n",
    "We can use the variable \n",
    "\n",
    "$$Z = X + c \\left(Y - \\mu_i\\right),$$\n",
    "\n",
    "instead of $X_i$ as the estimate of the integral. It can then be shown that $E\\left(X\\right) = E\\left(Z\\right)$, since\n",
    "\n",
    "$$E\\left(Z\\right) = E\\left(X\\right) +E\\left(c \\left(Y - \\mu_i\\right)\\right) $$\n",
    "$$ = E\\left(X\\right) + c \\left(E\\left(Y \\right) - E \\left(\\mu_i\\right)\\right) = E\\left(X\\right) + c \\left(\\mu_i - \\mu_i\\right) =E\\left(X_i\\right). $$\n",
    "\n",
    "From the slides we also know that choosing the optimal $c = -\\frac{Cov(X,Y)}{Var(Y)}$, results in a variance of $ Z $\n",
    "\n",
    "$$ Var(Z) = Var(X) - \\frac{Cov(X,Y)^2}{Var(Y)}. $$\n",
    "\n",
    "For this specific problem we are given $X_i = e^{U_i}$, and it is natural to choose $Y_i = U_i$. This again exploits the covariance between $U_i$ and $X_i$, though this time negative correlation is not a requirement, as the covariance is squared. It should just be non-zero. \n",
    "As $E\\left(U_i\\right) = \\frac{1}{2}$  we get\n",
    "\n",
    "$$Z_i = e^{U_i} + c \\left(U_i - \\frac{1}{2}\\right),$$\n",
    "\n",
    "with $c\\approx 0.14086.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Control Variates\n",
      "Mean is 1.71, with 95% confidence interval [1.7,1.72]\n"
     ]
    }
   ],
   "source": [
    "def controlVariates(n, alpha):\n",
    "    U = rnd.uniform(size = n)\n",
    "    Xs = np.exp(U)\n",
    "    dof = len(Xs) - 1\n",
    "    meanZ = np.mean(Xs)\n",
    "    cov = np.mean(U * Xs) - np.mean(U) * np.mean(Xs) \n",
    "    varZ = np.var(Xs) - cov**2 / np.var(U)\n",
    "    s = np.sqrt(varZ / len(Xs))\n",
    "    a = stats.t.ppf(alpha/2, dof)\n",
    "    b = stats.t.ppf(1 - alpha/2, dof)\n",
    "    print(\"For Control Variates\")\n",
    "    print(f\"Mean is {round(meanZ,2)}, with 95% confidence interval [{round(meanZ + s * a,2)},{round(meanZ + s * b,2)}]\")\n",
    "controlVariates(n, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNCHANGED\n",
    "### 4) Statified Sampling\n",
    "Stratified sampling attemts to lower variance by (almost) gaurantying samples from the entire sample space, by cutting the sample space into $m$ pieces, and then sampling a number of variables from each. Here weÂ´ll use $m = 10$ even intervals, to ensure even computational cost to the other methods, 10 $U_i$'s are generated in each interval.\n",
    "\n",
    "The method then takes one $U_i$ from each interval and creates a single variable $W_i$ \n",
    "\n",
    "$$W_i = \\frac{\\sum_{k=1}^{m} X_{i,k}}{m}, $$\n",
    "\n",
    "where $ k $ now denotes which interval the $X_i$ comes from. Still $X_i = e^{U_i}$, or $X_{i,k} = e^{U_{i,k}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Stratified Sampling :\n",
      "Mean is 1.72, with 95% confidence interval [1.71,1.733]\n"
     ]
    }
   ],
   "source": [
    "def stratSamples(n):\n",
    "    num_ints = 10\n",
    "    k = 1 / num_ints\n",
    "    Xs = np.zeros(n)\n",
    "    Us = np.zeros(num_ints)\n",
    "    for j in range(n):\n",
    "        for i in range(num_ints):\n",
    "            a = k * i\n",
    "            b = a + k \n",
    "            U = rnd.uniform(a, b, size = 1)\n",
    "            Us[i] = U\n",
    "        Xs[j] = np.mean(np.exp(Us))\n",
    "    return Xs\n",
    "n = 10\n",
    "Xs_stratified = stratSamples(n)\n",
    "tConf(Xs_stratified, alpha, \"Stratified Sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4) Observations\n",
    "The Crude MC method gives a very wide CI\n",
    "All the variance reduction methods have succesfully narrowed the CI. We had the largest success with Control Variates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGED\n",
    "### 5) Use control variates to reduce the variance of the estimator in exercise 4\n",
    "We'll use the arrival intervals as control variate, i.e. control variate $C_i \\sim Exp(\\lambda)$, note the difference between arrival intervals, which are just sampled, and arrival times which are the actual times customers arrive at, which is the cummulative arrival intervals.\n",
    "\n",
    "Using the formula\n",
    "\n",
    "$$Z_i = X_i + c \\left(C_i - 1 \\right), $$\n",
    "\n",
    "$X_i$ is a list of bools of wether the customer with arrival interval $C_i$. Correlation is expected between $X_i$ and $C_i$ as a customer arriving quickly after another (small $C_i$) would presumably be blocked more often, as other customers have not had time to be served yet. We ofcourse know the mean of $C_i$, and can find the optimal $c = \\frac{Cov\\left(X, C \\right)}{Var(C)}$ in each iteration. \n",
    "\n",
    "We're concerned with the mean of $X_i$, which is the blocking probability, and $Z_i$ is constructed to have the same mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import scipy.stats as stats\n",
    "import math as math\n",
    "from scipy.stats import expon\n",
    "import numpy as np\n",
    "from discrete_event import Customer, main_loop, confidence_intervals, erlang_b, main_loop_array\n",
    "\n",
    "#arrival time differences are exponentially distributed\n",
    "lam = 1\n",
    "total_customers = 10000\n",
    "m = 10\n",
    "s = 8\n",
    "repititions = 10\n",
    "#arrival time differences are exponentially distributed\n",
    "arrival_interval = lambda : np.random.exponential(1/lam, size = total_customers)\n",
    "service_time =lambda : expon.rvs(scale = s, size = total_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated blocking probability 12.3%\n",
      "True blocking probability 12.2% (From Erlang formula)\n",
      "95% CI for mean of blocking probability [0.1194, 0.1259]\n",
      "Interval width 0.0065\n"
     ]
    }
   ],
   "source": [
    "blocked = main_loop(arrival_interval, service_time, m, repititions = repititions)/total_customers\n",
    "#print(\"Blocking probability\", blocked/total_customers * 100)\n",
    "#confidence interval for the mean\n",
    "theta = np.mean(blocked)\n",
    "confint = confidence_intervals(blocked)\n",
    "print(f\"Estimated blocking probability {round(theta,3)*100}%\\nTrue blocking probability {round(erlang_b(m, lam*s),3) *100}% (From Erlang formula)\" )\n",
    "print(f\"95% CI for mean of blocking probability [{round(confint[0],4)}, {round(confint[1],4)}]\")\n",
    "print(\"Interval width\", round(confint[1]-confint[0],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated blocking probability 11.899999999999999%\n",
      "True blocking probability 12.2% (From Erlang formula)\n",
      "95% CI for mean of blocking probability [0.1208, 0.1251]\n",
      "Interval width 0.0043\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "n = 10\n",
    "Zs = []\n",
    "\n",
    "for i in range(n):\n",
    "    arrival_intervals = np.random.exponential(1/lam, size = total_customers)\n",
    "    service_times = expon.rvs(scale = s, size = total_customers)\n",
    "    blocked = main_loop_array(arrival_intervals, service_times, m)#/total_customers\n",
    "    # Construct new variable\n",
    "    c = -np.cov(arrival_intervals, blocked)[0,1] / np.var(arrival_intervals)\n",
    "    Z = blocked + c * (arrival_intervals - 1)\n",
    "    Zs.append(np.mean(Z))\n",
    "\n",
    "tehta_Z = np.mean(Zs)\n",
    "confint_Z = confidence_intervals(Zs)\n",
    "print(f\"Estimated blocking probability {round(theta,3)*100}%\\nTrue blocking probability {round(erlang_b(m, lam*s),3) *100}% (From Erlang formula)\" )\n",
    "print(f\"95% CI for mean of blocking probability [{round(confint_Z[0],4)}, {round(confint_Z[1],4)}]\")\n",
    "print(\"Interval width\", round(confint_Z[1]-confint_Z[0],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Reduce variance for the difference between solutions with poisson arrivals and hyperexponential renewal process in exercise 4\n",
    "\n",
    "Do this using Common Random Numbers (CRN). Using CRN we should be able to reduce the width of the CI og the difference in number of blocked customers between the two arrival processes. \n",
    "\n",
    "Using non-CRN's it should require 5 differerent processes of generating arrivals and leaves to compare the two processes. 2 generates the serice times for the processes, one generates arrivals for the poisson process and 2 generates renewals for the hyperexponential arrivals.\n",
    "\n",
    "When using CRN's this can be reduced to 3. The services times can be generated from the same $U$, since they should be the same here. We can use a single $U$ as the exponential for the poisson and hyperexponential processes. We also need one more $U$ to flip between the two exponentials in the hyperexponential distribution.\n",
    "\n",
    "Both test runs predict more blocked customers when assuming a hyperexponential renewal process. The width of the CI when using CRN's can be reduced to $\\sim 1/3$ compared to just simulating the two processes independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect as bisect\n",
    "class Customer:\n",
    "    def __init__(self, arrival_time, service_time):\n",
    "        self.service_time = service_time\n",
    "        self.blocked = False\n",
    "        \n",
    "        self.event = \"arrival\"\n",
    "        self.event_time = arrival_time\n",
    "      \n",
    "                \n",
    "    def arrive(self, servers, event_list):\n",
    "        if servers < 1:\n",
    "            self.blocked = True\n",
    "            return servers\n",
    "        else:\n",
    "            servers -= 1\n",
    "            servers = max(servers, 0)\n",
    "            self.event = \"departure\"\n",
    "            self.event_time += self.service_time\n",
    "            bisect.insort(event_list, self, key=lambda x: x.event_time)\n",
    "            return servers\n",
    "    \n",
    "    def depart(self, servers):\n",
    "        servers += 1\n",
    "        servers = min(servers, m)\n",
    "        return servers\n",
    "\n",
    "from distributions import getExponential, getUniform\n",
    "\n",
    "def main_loop(event_list, m, repititions = 10):\n",
    "\n",
    "    blocked = 0\n",
    "    for i in range(repititions):\n",
    "        event_list.sort(key=lambda x: x.event_time)\n",
    "        open_servers = m\n",
    "        while event_list:\n",
    "            event = event_list.pop(0)\n",
    "            if event.event == \"arrival\":\n",
    "                open_servers = event.arrive(open_servers, event_list)\n",
    "                blocked += event.blocked\n",
    "            elif event.event == \"departure\":\n",
    "                open_servers = event.depart(open_servers)\n",
    "    return blocked\n",
    "\n",
    "num_customers = 10000\n",
    "lam = 1\n",
    "s = 1/8\n",
    "# Generate two eventlists\n",
    "p1 = 0.8\n",
    "lam1 = 0.8333\n",
    "p2 = 0.2\n",
    "lam2 = 5.0\n",
    "\n",
    "def generateHexp(Us, Us2, p2, lam1, lam2):\n",
    "    Xs = np.zeros(len(Us))\n",
    "    for i in range(len(Us)):\n",
    "        if Us2[i] < p2:\n",
    "            Xs[i] = -np.log(Us[i]) / lam2\n",
    "        else:\n",
    "            Xs[i] = -np.log(Us[i]) / lam1\n",
    "    return Xs\n",
    "\n",
    "m = 10\n",
    "rep = 5\n",
    "blocked_hexp = np.zeros(rep)\n",
    "blocked_poisson = np.zeros(rep)\n",
    "blocked_poisson_common = np.zeros(rep)\n",
    "blocked_hexp_common = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "\n",
    "    Us1 = rnd.uniform(0,1,num_customers)\n",
    "    Us2 = rnd.uniform(0,1,num_customers)\n",
    "    Us3 = rnd.uniform(0,1,num_customers)\n",
    "    service_intervals = -np.log(Us1) / s\n",
    "    poisson_arrival_times = np.cumsum(-np.log(Us2) / lam)\n",
    "    hexp_arrival_times = np.cumsum(generateHexp(Us2, Us3, p2, lam1, lam2))\n",
    "\n",
    "    event_list_poisson = [Customer(poisson_arrival_times[i], service_intervals[i]) for i in range(num_customers)]\n",
    "    event_list_hexp = [Customer(hexp_arrival_times[i], service_intervals[i]) for i in range(num_customers)]\n",
    "\n",
    "    blocked_poisson_common[i] = main_loop(event_list_poisson, m, repititions=1)\n",
    "    blocked_hexp_common[i] = main_loop(event_list_hexp, m, repititions=1)\n",
    "\n",
    "    Us1 = rnd.uniform(0,1,num_customers)\n",
    "    Us2 = rnd.uniform(0,1,num_customers)\n",
    "    Us3 = rnd.uniform(0,1,num_customers)\n",
    "    Us4 = rnd.uniform(0,1,num_customers)\n",
    "    Us5 = rnd.uniform(0,1,num_customers)\n",
    "    service_intervals1 = -np.log(Us2) / s\n",
    "    service_intervals2 = -np.log(Us3) / s\n",
    "\n",
    "    poisson_arrival_times = np.cumsum(-np.log(Us1) / lam)\n",
    "    hexp_arrival_times = np.cumsum(generateHexp(Us4, Us5, p2, lam1, lam2))\n",
    "\n",
    "    event_list_poisson = [Customer(poisson_arrival_times[i], service_intervals1[i]) for i in range(num_customers)]\n",
    "    event_list_hexp = [Customer(hexp_arrival_times[i], service_intervals2[i]) for i in range(num_customers)]\n",
    "\n",
    "    blocked_poisson[i] = main_loop(event_list_poisson, m, repititions=1)\n",
    "    blocked_hexp[i] = main_loop(event_list_hexp,m, repititions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For common random numbers\n",
      "Mean is -132.0, with confidence interval [-170.009,-93.991]\n",
      "Width of CI = 76.017\n",
      "For independent random numbers\n",
      "Mean is -152, with confidence interval [-284.092,-19.908]\n",
      "Width of CI = 264.184\n"
     ]
    }
   ],
   "source": [
    "theta_crn = blocked_poisson_common - blocked_hexp_common\n",
    "theta_irn = blocked_poisson - blocked_hexp\n",
    "\n",
    "mean_theta_crn = round(np.mean(theta_crn),0)\n",
    "var_theta_crn = np.var(theta_crn)\n",
    "s = np.sqrt(var_theta_crn / len(theta_crn))\n",
    "dof = len(theta_crn)-1\n",
    "a = stats.t.ppf(alpha/2, dof)\n",
    "b = stats.t.ppf(1 - alpha/2,dof)\n",
    "print(\"For common random numbers\")\n",
    "print(f\"Mean is {mean_theta_crn}, with confidence interval [{round(mean_theta_crn + s * a,3)},{round(mean_theta_crn + s * b,3)}]\")\n",
    "print(f\"Width of CI = {round(np.abs(mean_theta_crn + s * a - mean_theta_crn - s*b),3)}\")\n",
    "\n",
    "\n",
    "mean_theta_irn = int(np.mean(theta_irn))\n",
    "var_theta_irn = np.var(theta_irn)\n",
    "s = np.sqrt(var_theta_irn / len(theta_irn))\n",
    "print(\"For independent random numbers\")\n",
    "print(f\"Mean is {mean_theta_irn}, with confidence interval [{round(mean_theta_irn + s * a,3)},{round(mean_theta_irn + s * b,3)}]\")\n",
    "print(f\"Width of CI = {round(abs(mean_theta_irn + s * a - mean_theta_irn - s*b),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Using a Crude Monte Carlo estimator vs Importance Sampling\n",
    "Attempt to estimate the probality $Z > a$ for $Z\\sim N(0,1)$ for $a = 2,4$.\n",
    "Do this using a crude monte carlo estimator and with importance sampling.\n",
    "\n",
    "Using importance sampling set $h(z) = z > a$. We'll choose $g(x)$ to also be a normal distribution, with the same variance as $f(x)$, though with mean $a$ instead. This means $g$ samples around $a$ more often. We thus have to sample fewer points to get an accurate estimate. \n",
    "\n",
    "Notice $n = 10000$ with importance sampling gives significant digits, while the Crude Estimator needs $n  = 100000$ to get a significant digit. A lot of time can be saved.\n",
    "\n",
    "As long as a is small enough e.g. $a = 2$ Importance Sampling does not seem nescesarry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 10000 samples\n",
      "Crude probability z larger than 2 is 2.27%\n",
      "Crude probability z larger than 4 is 0.003%\n",
      "Probability z larger than 2 with importance sampling 2.3139%\n",
      "Probability z larger than 4 with importance sampling 0.0031%\n"
     ]
    }
   ],
   "source": [
    "def crudeMonteCarloNorm(a,n):\n",
    "    Us = rnd.normal(size = n)\n",
    "    return sum(Us > a) / n\n",
    "n = 10000\n",
    "n2 = 100000\n",
    "p1 = crudeMonteCarloNorm(2, n2)\n",
    "p2 = crudeMonteCarloNorm(4, n2)\n",
    "\n",
    "print(f\"With {n} samples\")\n",
    "print(f\"Crude probability z larger than 2 is {round(p1 * 100,5)}%\")\n",
    "print(f\"Crude probability z larger than 4 is {round(p2 * 100,5)}%\")\n",
    "\n",
    "def h(a,x):\n",
    "    return x > a\n",
    "\n",
    "sigma1 = 1\n",
    "a = 2\n",
    "ys = rnd.normal(loc = a,scale = sigma1,size = n)\n",
    "fy = stats.norm.pdf(ys)\n",
    "gy = stats.norm.pdf(ys, loc = a, scale = sigma1)\n",
    "zs = fy / gy * h(a,ys)\n",
    "print(f\"Probability z larger than 2 with importance sampling {round(np.mean(zs) * 100, 4)}%\")\n",
    "\n",
    "a = 4\n",
    "ys = rnd.normal(loc = a,scale = sigma1,size = n)\n",
    "fy = stats.norm.pdf(ys)\n",
    "gy = stats.norm.pdf(ys, loc = a, scale = sigma1)\n",
    "zs = fy / gy * h(a,ys)\n",
    "\n",
    "print(f\"Probability z larger than 4 with importance sampling {round(np.mean(zs) * 100, 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8)\n",
    "Analytically set\n",
    "$$f(x) = \\mathbf{1}_{0 \\leq x \\leq 1}$$\n",
    "$$h(x) = e^x$$\n",
    "$$g(x) = \\lambda e ^{-\\lambda x}.$$\n",
    "\n",
    "We want to find the variance of \n",
    "\n",
    "$$\\frac{f(x)h(x)}{g(x)}.$$\n",
    "\n",
    "Write\n",
    "$$Var\\left(\\frac{f(x)h(x)}{g(x)}\\right) = E\\left(\\left(\\frac{f(x)h(x)}{g(x)}\\right)^2\\right)  - E\\left(\\frac{f(x)h(x)}{g(x)}\\right)^2 $$\n",
    "$$ = \\int_{-\\infty}^{\\infty} \\left(\\frac{f(x)h(x)}{g(x)}\\right)^2 g(x)\\, \\mathrm{d}x - \\left(\\int_{-\\infty}^{\\infty} \\frac{f(x)h(x)}{g(x)} g(x)\\, \\mathrm{d}x\\right) ^2.$$\n",
    "\n",
    "The second integral is simply to rewrite\n",
    "$$\\left(\\int_{-\\infty}^{\\infty} \\frac{f(x)h(x)}{g(x)} g(x)\\, \\mathrm{d}x\\right) ^2 = \\left(\\int_{-\\infty}^{\\infty} f(x)h(x)\\, \\mathrm{d}x\\right) ^2$$\n",
    "$$ = \\left(\\int_{0}^{1} f(x)e^x\\, \\mathrm{d}x\\right) ^2.$$\n",
    "\n",
    "The first integral is slightly less pretty\n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} \\left(\\frac{f(x)h(x)}{g(x)}\\right)^2 g(x)\\, \\mathrm{d}x = \\int_{-\\infty}^{\\infty} \\frac{f(x)^2h(x)^2}{g(x)} \\, \\mathrm{d}x$$\n",
    "$$ = \\int_{-\\infty}^{\\infty} \\frac{f(x)^2e^{2x}}{\\lambda e^{-\\lambda x}} \\, \\mathrm{d}x = \\frac{1}{\\lambda}\\int_{-\\infty}^{\\infty} f(x)^2e^{2x+\\lambda x} \\, \\mathrm{d}x$$\n",
    "$$ =\\frac{1}{\\lambda}\\int_{0}^{1} e^{(2 +\\lambda )x} \\, \\mathrm{d}x .$$\n",
    "\n",
    "Collecting:\n",
    "$$Var\\left(\\frac{f(x)h(x)}{g(x)}\\right) = \\frac{1}{\\lambda}\\int_{0}^{1} e^{(2 +\\lambda )x} \\, \\mathrm{d}x - \\left(\\int_{0}^{1} f(x)e^x\\, \\mathrm{d}x\\right) ^2$$\n",
    "\n",
    "From Maple:\n",
    "$$Var\\left(\\frac{f(x)h(x)}{g(x)}\\right) =\\frac{-1 + e^{2 + \\lambda}}{2 + \\lambda} - (e-1)^2.$$\n",
    "\n",
    "Using a numerical solver to minimize this expression gives $\\lambda \\approx 1.354828644. $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical variance at optimal lambda is 2.9803500419443325\n",
      "Actual variance of sample at optimal lambda is 3.1416055177375855\n",
      "Using importance sampling\n",
      "Mean is 1.7106, with confidence interval [1.676,1.745]\n",
      "Width of CI = 0.069\n",
      "Using Crude Monte Carlo\n",
      "Mean is 1.7172, with confidence interval [1.708,1.727]\n",
      "Width of CI = 0.019\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lambda_opt = 1.354828644\n",
    "\n",
    "def var_anal(lam):\n",
    "    return (-1 + np.exp(2 + lam))/(lam*(2 + lam)) - (np.exp(1) - 1)^2\n",
    "\n",
    "def variance(lam, n):\n",
    "    Us1 = rnd.uniform(size = n)\n",
    "    Us2 = rnd.uniform(size = n)\n",
    "    return 1/lam * np.mean(np.exp((2+lam)*Us1)) - np.mean(np.exp(Us2))**2\n",
    "\n",
    "lams = np.linspace(0.09, 5, 1000)\n",
    "ys = np.zeros(1000)\n",
    "for i in range(len(lams)):\n",
    "    ys[i] = variance(lams[i], 10000)\n",
    "print(\"Theoretical variance at optimal lambda is\", np.min(ys))\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(lams, ys)\n",
    "\n",
    "def g(x,lam):\n",
    "    return lam * np.exp(-lam * x)\n",
    "\n",
    "def f(x):\n",
    "    b1 = x > 0\n",
    "    b2 = x < 1\n",
    "    return b1 * b2\n",
    "def h(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "n = 10000\n",
    "lam = lambda_opt\n",
    "\n",
    "\n",
    "\n",
    "n = 10000\n",
    "Xs_crude = crudeMC(n)\n",
    "mean = np.mean(Xs_crude)\n",
    "var = np.var(Xs_crude)\n",
    "s = np.sqrt(var / len(Xs_crude))\n",
    "a = stats.norm.ppf(alpha/2)\n",
    "b = stats.norm.ppf(1 - alpha/2)\n",
    "print(\"Using Crude Monte Carlo\")\n",
    "print(f\"Mean is {round(mean,4)}, with confidence interval [{round(mean + s * a,3)},{round(mean + s * b,3)}]\")\n",
    "print(f\"Width of CI = {round(abs(mean + s * a - mean - s*b),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note here that the variance of our sample, when using the optimal lambda, is close to the variance we'ed expect given the plot. Using importance sampling with this $g(x)$ we would not expected to find a lower variance.\n",
    "\n",
    "We can try the same thing, now with $\\lambda  = 3.5$ , where we would expect to see a sample variance aroung $10$, which we indeed do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lambda = 3.5 we instead find a variance of 9.901624437913682\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "lam = 3.5\n",
    "ys = rnd.exponential(scale = 1/lam, size = n)\n",
    "\n",
    "zs = f(ys) * h(ys) / g(ys, lam)\n",
    "\n",
    "mean = np.mean(zs)\n",
    "var = np.var(zs)\n",
    "\n",
    "print(f\"Using lambda = {lam} we instead find a variance of\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Deriving the IS estimator for the mean of a Pareto distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pdf for a arbritray Pareto distribution is $f(x) = \\frac{k}{y} \\left(\\frac{\\beta}{y}\\right)^k$. From the lectures we know that the first moment distribution of a Pareto distribution is just a Pareto distribution with paramters $\\beta$ and $k-1$. Thus\n",
    "\n",
    "$$g(y) = \\frac{k-1}{y} \\left(\\frac{\\beta}{y}\\right)^{k-1}.$$\n",
    "\n",
    "As we're estimating the mean, set $h(y) =y.$ Now the IS estimator for the mean is\n",
    "\n",
    "$$\\frac{f(y)h(y)}{g(y)} = \\frac{\\frac{k}{y} \\left(\\frac{\\beta}{y}\\right)^k\\cdot y}{\\frac{k-1}{y} \\left(\\frac{\\beta}{y}\\right)^{k-1}} = \\frac{yk}{k-1}\\frac{\\left(\\frac{\\beta}{y}\\right)^k}{\\left(\\frac{\\beta}{y}\\right)^{k-1}} = \\frac{yk}{k-1} \\frac{\\beta}{y} = \\beta \\frac{k}{k-1}. $$\n",
    "Which we know is just the mean of the original Pareto distribution $f(x)$, i.e. we should be sampling exactly the mean! Which we do, with an exact CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using importance sampling to sample the mean of a pareto distribution using its first moment\n",
      "Mean is 2.0, with confidence interval [2.0,2.0]\n",
      "Width of CI = 0.0\n",
      "Exact solution for the Pareto distribution mean 2.0\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "def g(x):\n",
    "    return (k-1) /(x) * (1/x)**(k-1)\n",
    "\n",
    "def f(x):\n",
    "    return k /(x) * (1/x)**k\n",
    "def h(x):\n",
    "    return x\n",
    "\n",
    "n = 100\n",
    "lam = lambda_opt\n",
    "ys = rnd.exponential(scale = 1/lam, size = n)\n",
    "beta = 1\n",
    "zs = f(ys) * h(ys) / g(ys)\n",
    "alpha = 0.05\n",
    "mean = np.mean(zs)\n",
    "var = np.var(zs)\n",
    "s = np.sqrt(var / len(zs))\n",
    "a = stats.norm.ppf(alpha/2)\n",
    "b = stats.norm.ppf(1 - alpha/2)\n",
    "print(\"Using importance sampling to sample the mean of a pareto distribution using its first moment\") \n",
    "print(f\"Mean is {round(mean,4)}, with confidence interval [{round(mean + s * a,3)},{round(mean + s * b,3)}]\")\n",
    "print(f\"Width of CI = {round(abs(mean + s * a - mean - s*b),3)}\")\n",
    "\n",
    "print(f\"Exact solution for the Pareto distribution mean {k/(k-1) * beta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case sampling values from a constant value works out, because we know the mean of the Pareto distribution. This approach could be used, but it would be nesecary to know for certain that youÂ´re sampling from the right constant. It could be possible to choose a $g(x)$ such that $\\frac{h(x)f(x)}{g(x)}$ is a constant, which is not the mean of $f(x)$, in this case you would end ud with $100$% confidence, in something which is not correct. Gauranteing that you sample from the constant mean, would require you knowing the mean, but then there would be no reason for this approach.\n",
    "\n",
    "For the previous case $f(x) = \\lambda e^{-\\lambda x}$ use $g(x) = x e ^{-\\lambda x}$. To sample from only the mean get\n",
    "\n",
    "$$\\frac{x\\cdot \\lambda e^{-\\lambda x}}{x e ^{-\\lambda x}} = \\lambda.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.69084652e-04 5.82547562e-05 2.38576115e-04 2.36643190e-03\n",
      " 3.80846481e-04]\n",
      "0.5819767068693265\n",
      "Actual variance of sample at optimal lambda is 0.0007374226510054708\n",
      "Using importance sampling\n",
      "Mean is 1.7271, with confidence interval [1.727,1.728]\n",
      "Width of CI = 0.001\n"
     ]
    }
   ],
   "source": [
    "beta = 0.005\n",
    "k = 2\n",
    "def g(x, beta, k):\n",
    "    return 1/ (np.exp(1) - 1)\n",
    "def f(x):\n",
    "    return (x > 0) * (x < 1)\n",
    "def h(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "def pareto(beta, k, n = 10000): \n",
    "    Us = np.random.uniform(size = n)\n",
    "    Xs = beta * (Us**(-1/k)-1)\n",
    "    return Xs\n",
    "\n",
    "ys = pareto(beta, k)\n",
    "print(ys[0:5])\n",
    "\n",
    "\n",
    "zs = f(ys) * h(ys) / g(ys, beta, k)\n",
    "print(g(ys, beta, k))\n",
    "\n",
    "mean = np.mean(zs)\n",
    "var = np.var(zs)\n",
    "alpha = 0.05\n",
    "print(\"Actual variance of sample at optimal lambda is\", var)\n",
    "s = np.sqrt(var / len(zs))\n",
    "a = stats.norm.ppf(alpha/2)\n",
    "b = stats.norm.ppf(1 - alpha/2)\n",
    "print(\"Using importance sampling\")\n",
    "print(f\"Mean is {round(mean,4)}, with confidence interval [{round(mean + s * a,3)},{round(mean + s * b,3)}]\")\n",
    "print(f\"Width of CI = {round(abs(mean + s * a - mean - s*b),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
