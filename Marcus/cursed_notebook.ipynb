{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import numpy.random as rnd\n",
    "\n",
    "\n",
    "def metropolis_hastings(g,N,m, burn_in = None):\n",
    "    burn_in = burn_in if burn_in is not None else N // 10\n",
    "    #X and Y are random integers from 0 to m\n",
    "    U = np.random.uniform(0,1,N + burn_in)\n",
    "    X = np.zeros(N + burn_in,dtype = int)\n",
    "    X[0] = 3\n",
    "    #prob_of_sampling = np.minimum(g(X)/g(Y),np.ones(N))\n",
    "    #sample X with probability prob_of_sampling\n",
    "    for i in range(1,N+burn_in):\n",
    "        x = X[i-1]\n",
    "        y = np.random.randint(0,m+1)\n",
    "        \n",
    "        if U[i] <= min(g(y) / g(x),1) :\n",
    "            X[i] = y\n",
    "        else:\n",
    "            X[i] = x\n",
    "            \n",
    "    # X = np.where(U<prob_of_sampling,X,Y)\n",
    "    X = X[burn_in:]\n",
    "    return X\n",
    "\n",
    "def truncated_poisson_samples(lam, low, high, size=1, numvars = 1):\n",
    "    samples = []\n",
    "    while len(samples) < size:\n",
    "        x = np.random.poisson(lam, numvars)\n",
    "        if low <= x <= high:\n",
    "            samples.append(x)\n",
    "    return np.array(samples)\n",
    "\n",
    "def y_sampling_function(m):\n",
    "        def y_sampling():\n",
    "            y1 = np.random.randint(0,m+1)\n",
    "            y2 = np.random.randint(0,m+1-y1)\n",
    "            #create y as (y1,y2) or (y2,y1) with equal probability\n",
    "            return (y1,y2) if np.random.uniform(0,1) < 0.5 else (y2,y1)\n",
    "        return y_sampling\n",
    "    \n",
    "\n",
    "def metropolis_hastings_joint(g_joint,N, burn_in = None, y_sampling_func = y_sampling_function(10)):\n",
    "    burn_in = burn_in if burn_in is not None else N\n",
    "\n",
    "    #X and Y are random integers from 0 to m\n",
    "    U = np.random.uniform(0,1,N + burn_in)\n",
    "    X = np.zeros((N + burn_in,2),dtype = float)\n",
    "    X[0] = (1.0,1.0)\n",
    "    #prob_of_sampling = np.minimum(g(X)/g(Y),np.ones(N))\n",
    "    #sample X with probability prob_of_sampling\n",
    "    for i in range(1,N+burn_in):\n",
    "        x = X[i-1]\n",
    "        y = y_sampling_func()\n",
    "        if U[i] <= min(g_joint(y[0],y[1]) / g_joint(x[0],x[1]),1) :\n",
    "            X[i] = y\n",
    "        else:\n",
    "            X[i] = x\n",
    "    # X = np.where(U<prob_of_sampling,X,Y)\n",
    "    X = X[burn_in:]\n",
    "    return X\n",
    "\n",
    "def Gibbs(As, n, x0, m):\n",
    "    xs = [x0[0]]\n",
    "    ys = [x0[1]]\n",
    "    A1 = As[0]\n",
    "    A2 = As[1]\n",
    "    for k in range(1,n):\n",
    "        # Generate i and sample from j\n",
    "        i = xs[k-1]\n",
    "        num_classes_j = int(m - i + 1)\n",
    "        ps = np.zeros(num_classes_j)\n",
    "        k = 0\n",
    "        for j in range(num_classes_j):\n",
    "            ps[j] = A2**j / math.factorial(j)\n",
    "            k += A2**j / math.factorial(j)\n",
    "        ps /= k\n",
    "        j = rnd.choice(a=np.arange(num_classes_j), size= 1, p = ps)[0]\n",
    "\n",
    "        ys.append(j)\n",
    "        # Newest j has already been found\n",
    "        num_classes_i = int(m-j + 1)\n",
    "        ps = np.zeros(num_classes_i )\n",
    "        k = 0\n",
    "        for i in range(num_classes_i):\n",
    "            ps[i] = A2**i / math.factorial(i)\n",
    "            k += A2**i / math.factorial(i)\n",
    "        ps /= k\n",
    "        i = rnd.choice(a=np.arange(num_classes_i), size=1, p = ps)[0]\n",
    "        xs.append(i)\n",
    "    return np.array(xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def LCG(xval, M, a, c, N):\n",
    "    x = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        xval = (a*xval + c) % M\n",
    "        x[i] = xval\n",
    "    x/=M\n",
    "    return x\n",
    "\n",
    "def KS_test(randn):\n",
    "    Ftrue = np.arange(0,1,1/len(randn))\n",
    "    #import uniform distribution cdf\n",
    "    F = uniform.cdf(randn)\n",
    "    #calculate max difference\n",
    "    D = np.max(np.abs(Ftrue - F))\n",
    "    #calculate p value\n",
    "    n = len(randn)\n",
    "    pval = 1 - np.exp(-2*n*D**2)\n",
    "    \n",
    "    return D, pval\n",
    "\n",
    "#calculate chi squared\n",
    "def chisquare_test(randn, k):\n",
    "    n = len(randn)\n",
    "    p = 1/k\n",
    "    test = 0\n",
    "    for i in range(k):\n",
    "        xval = randn[(i/k < randn)*(randn < (i+1)/k)]\n",
    "        ni = len(xval)\n",
    "        test += (ni - n*p)**2/(n*p)     \n",
    "    pval = 1 - chi2.cdf(test, k-1)\n",
    "    return test, pval\n",
    "\n",
    "def run_test_1(randn):\n",
    "    #median value\n",
    "    median = np.median(randn)\n",
    "    #number of observations below median\n",
    "    possamps = randn < median\n",
    "    negsamps = randn > median\n",
    "    posruns = 0\n",
    "    negruns = 0\n",
    "    n1 = np.sum(possamps)\n",
    "    n2 = np.sum(negsamps)\n",
    "    n = n1+n2\n",
    "    for i in range(len(randn)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if possamps[i] != possamps[i-1] and possamps[i] == True:\n",
    "            posruns += 1\n",
    "        if negsamps[i] != negsamps[i-1] and negsamps[i] == True:\n",
    "            negruns += 1\n",
    "    T = posruns + negruns\n",
    "    #normal cdf\n",
    "\n",
    "    mean = 2*n1*n2/n + 1\n",
    "    var = np.exp(np.log(2)+np.log(n1)+np.log(n2)+np.log(2*n1*n2 - n)-np.log(n**2)-np.log((n-1)))\n",
    "    Z = (T-mean)/np.sqrt(var)\n",
    "    pval = 1 - norm.cdf(Z)\n",
    "    return T, pval\n",
    "\n",
    "def run_test_2(randn):\n",
    "    # up/down \n",
    "    run_lengths = []\n",
    "    current_run_length = 1\n",
    "    for i in range(1, len(randn)):\n",
    "        if randn[i] > randn[i-1]:\n",
    "            current_run_length = min(current_run_length + 1, 6)\n",
    "        else:\n",
    "            run_lengths.append(current_run_length)\n",
    "            current_run_length = 1\n",
    "    #get vector of count for each run length\n",
    "    R, _ = np.histogram(run_lengths, bins=6)\n",
    "    \n",
    "    A  = np.array([\n",
    "        [4529.4, 9044.9, 13568, 18091, 22615, 27892],\n",
    "        [9044.9, 18097, 27139, 36187, 45234, 55789],\n",
    "        [13568, 27139, 40721, 54281, 67852, 83685],\n",
    "        [18091, 36187, 54281, 72414, 90470, 111580],\n",
    "        [22615, 45234, 67852, 90470, 113262, 139476],\n",
    "        [27892, 55789, 83685, 111580, 139476, 172860]\n",
    "        ])\n",
    "    B = np.array([1/6, 5/24, 11/120, 19/720, 29/5040, 1/840])\n",
    "    n = len(randn)\n",
    "    Z = (R-B*n).T@A@(R-B*n)/(n-6)\n",
    "    #chisquare test\n",
    "    pval = 1 - chi2.cdf(Z, 6)\n",
    "    return Z, pval\n",
    "\n",
    "def run_test_3(randn):\n",
    "    n = len(randn)\n",
    "    updown = np.zeros(n-1, dtype=bool)\n",
    "    for i in range(1, n):\n",
    "        updown[i-1] = randn[i] > randn[i-1]\n",
    "    #count number of runs\n",
    "    runs = []\n",
    "    current_run = 1\n",
    "    for i in range(1, n-1):\n",
    "        if updown[i] != updown[i-1]:\n",
    "            runs.append(current_run)\n",
    "            current_run = 1\n",
    "        else:\n",
    "            current_run += 1\n",
    "    # number of unique runs\n",
    "    X = len(runs)\n",
    "    Z = (X - (2*n-1)/3)/np.sqrt((16*n-29)/90)\n",
    "    p = 2*(1 - norm.cdf(abs(Z)))\n",
    "    return Z, p\n",
    "\n",
    "def correlation_coefficient(randn, h=2):\n",
    "    c = np.sum(randn[:-h]*randn[h:])/len(randn)\n",
    "    Z = (c - 1/4)/np.sqrt(7/(144*len(randn)))\n",
    "    p = 2*(1 - norm.cdf(abs(Z)))\n",
    "    return c, p\n",
    "\n",
    "def do_all_tests(randn):\n",
    "    D, pval1 = KS_test(randn)\n",
    "    test1, pval2 = chisquare_test(randn, len(randn)//20)\n",
    "    test2, pval3 = run_test_1(randn)\n",
    "    test3, pval4 = run_test_2(randn)\n",
    "    test4, pval5 = run_test_3(randn)\n",
    "    c, pval6 = correlation_coefficient(randn)\n",
    "    # print results\n",
    "    print('KS test: D =', D, 'p-value =', pval1)\n",
    "    print('Chi-square test: test =', test1, 'p-value =', pval2)\n",
    "    print('Run test 1: test =', test2, 'p-value =', pval3)\n",
    "    print('Run test 2: test =', test3, 'p-value =', pval4)\n",
    "    print('Run test 3: test =', test4, 'p-value =', pval5)\n",
    "    print('Correlation coefficient: c =', c, 'p-value =', pval6)\n",
    "    # dictionary of results\n",
    "    results = {'KS test': (D, pval1), 'Chi-square test': (test1, pval2), 'Run test 1': (test2, pval3), 'Run test 2': (test3, pval4), 'Run test 3': (test4, pval5), 'Correlation coefficient': (c, pval6)}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bisect\n",
    "import math\n",
    "\n",
    "\n",
    "class Customer:\n",
    "    def __init__(self, arrival_time, service_time):\n",
    "        self.service_time = service_time\n",
    "        self.blocked = False\n",
    "        \n",
    "        self.event = \"arrival\"\n",
    "        self.event_time = arrival_time\n",
    "      \n",
    "                \n",
    "    def arrive(self, servers, event_list):\n",
    "        if servers < 1:\n",
    "            self.blocked = True\n",
    "            return servers\n",
    "        else:\n",
    "            servers -= 1\n",
    "            servers = max(servers, 0)\n",
    "            self.event = \"departure\"\n",
    "            self.event_time += self.service_time\n",
    "            bisect.insort(event_list, self, key=lambda x: x.event_time)\n",
    "            return servers\n",
    "    \n",
    "    def depart(self, servers, m):\n",
    "        servers += 1\n",
    "        servers = min(servers, m)\n",
    "        return servers\n",
    "    \n",
    "\n",
    "def main_loop(arrival_interval, service_time, m, repititions = 10):\n",
    "    blocked = np.zeros(repititions)\n",
    "    for i in range(repititions):\n",
    "        arrival_intervals = arrival_interval()\n",
    "        service_times = service_time()\n",
    "        arrival_times = np.cumsum(arrival_intervals)\n",
    "        event_list = [Customer(arrival_times[i],service_times[i]) for i in range(len(arrival_times))]\n",
    "        event_list.sort(key=lambda x: x.event_time)\n",
    "        open_servers = m\n",
    "        while event_list:\n",
    "            event = event_list.pop(0)\n",
    "            if event.event == \"arrival\":\n",
    "                open_servers = event.arrive(open_servers, event_list)\n",
    "                blocked[i] += event.blocked\n",
    "            elif event.event == \"departure\":\n",
    "                open_servers = event.depart(open_servers, m)\n",
    "    return blocked\n",
    "\n",
    "\n",
    "def confidence_intervals(samples):\n",
    "    emp_mean = np.mean(samples)\n",
    "    emp_std = np.std(samples)\n",
    "    t = 1.96\n",
    "    return (emp_mean - t*emp_std/np.sqrt(len(samples)), emp_mean + t*emp_std/np.sqrt(len(samples)))\n",
    "\n",
    "#Erlang B formula\n",
    "def erlang_b(m, A):\n",
    "    return (A**m/math.factorial(m))/np.sum([A**i/math.factorial(i) for i in range(m+1)])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
