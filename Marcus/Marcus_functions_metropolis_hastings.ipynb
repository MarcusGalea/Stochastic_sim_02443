{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import numpy.random as rnd\n",
    "\n",
    "\n",
    "def metropolis_hastings(g,N,m, burn_in = None):\n",
    "    burn_in = burn_in if burn_in is not None else N // 10\n",
    "    #X and Y are random integers from 0 to m\n",
    "    U = np.random.uniform(0,1,N + burn_in)\n",
    "    X = np.zeros(N + burn_in,dtype = int)\n",
    "    X[0] = 3\n",
    "    #prob_of_sampling = np.minimum(g(X)/g(Y),np.ones(N))\n",
    "    #sample X with probability prob_of_sampling\n",
    "    for i in range(1,N+burn_in):\n",
    "        x = X[i-1]\n",
    "        y = np.random.randint(0,m+1)\n",
    "        \n",
    "        if U[i] <= min(g(y) / g(x),1) :\n",
    "            X[i] = y\n",
    "        else:\n",
    "            X[i] = x\n",
    "            \n",
    "    # X = np.where(U<prob_of_sampling,X,Y)\n",
    "    X = X[burn_in:]\n",
    "    return X\n",
    "\n",
    "def truncated_poisson_samples(lam, low, high, size=1, numvars = 1):\n",
    "    samples = []\n",
    "    while len(samples) < size:\n",
    "        x = np.random.poisson(lam, numvars)\n",
    "        if low <= x <= high:\n",
    "            samples.append(x)\n",
    "    return np.array(samples)\n",
    "\n",
    "def y_sampling_function(m):\n",
    "        def y_sampling():\n",
    "            y1 = np.random.randint(0,m+1)\n",
    "            y2 = np.random.randint(0,m+1-y1)\n",
    "            #create y as (y1,y2) or (y2,y1) with equal probability\n",
    "            return (y1,y2) if np.random.uniform(0,1) < 0.5 else (y2,y1)\n",
    "        return y_sampling\n",
    "    \n",
    "\n",
    "def metropolis_hastings_joint(g_joint,N, burn_in = None, y_sampling_func = y_sampling_function(10)):\n",
    "    burn_in = burn_in if burn_in is not None else N\n",
    "\n",
    "    #X and Y are random integers from 0 to m\n",
    "    U = np.random.uniform(0,1,N + burn_in)\n",
    "    X = np.zeros((N + burn_in,2),dtype = float)\n",
    "    X[0] = (1.0,1.0)\n",
    "    #prob_of_sampling = np.minimum(g(X)/g(Y),np.ones(N))\n",
    "    #sample X with probability prob_of_sampling\n",
    "    for i in range(1,N+burn_in):\n",
    "        x = X[i-1]\n",
    "        y = y_sampling_func()\n",
    "        if U[i] <= min(g_joint(y[0],y[1]) / g_joint(x[0],x[1]),1) :\n",
    "            X[i] = y\n",
    "        else:\n",
    "            X[i] = x\n",
    "    # X = np.where(U<prob_of_sampling,X,Y)\n",
    "    X = X[burn_in:]\n",
    "    return X\n",
    "\n",
    "def Gibbs(As, n, x0, m):\n",
    "    xs = [x0[0]]\n",
    "    ys = [x0[1]]\n",
    "    A1 = As[0]\n",
    "    A2 = As[1]\n",
    "    for k in range(1,n):\n",
    "        # Generate i and sample from j\n",
    "        i = xs[k-1]\n",
    "        num_classes_j = int(m - i + 1)\n",
    "        ps = np.zeros(num_classes_j)\n",
    "        k = 0\n",
    "        for j in range(num_classes_j):\n",
    "            ps[j] = A2**j / math.factorial(j)\n",
    "            k += A2**j / math.factorial(j)\n",
    "        ps /= k\n",
    "        j = rnd.choice(a=np.arange(num_classes_j), size= 1, p = ps)[0]\n",
    "\n",
    "        ys.append(j)\n",
    "        # Newest j has already been found\n",
    "        num_classes_i = int(m-j + 1)\n",
    "        ps = np.zeros(num_classes_i )\n",
    "        k = 0\n",
    "        for i in range(num_classes_i):\n",
    "            ps[i] = A2**i / math.factorial(i)\n",
    "            k += A2**i / math.factorial(i)\n",
    "        ps /= k\n",
    "        i = rnd.choice(a=np.arange(num_classes_i), size=1, p = ps)[0]\n",
    "        xs.append(i)\n",
    "    return np.array(xs), np.array(ys)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
